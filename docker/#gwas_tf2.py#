import os
import sys
import numpy as np
import pandas as pd 
import tensorflow as tf
from scipy.stats import f
import time
import herit
import limix 
import h5py


# set defaults 
m = 1
mac_min = 5
batch_size =  500000 

X_file = '../imputed_snps_binary.hdf5'
Y_file = '../gp_at/phenos_f/FT10.csv'
K_file = '../kinship_ibs_binary_mac5.h5py'

Y_file = 'gwas_sample_data/KE_pheno.csv'
K_file = 'gwas_sample_data/K.csv'
X_file = 'gwas_sample_data/KE_geno.csv'



for i in range (1,len(sys.argv),2):
    if sys.argv[i] == "-x":
        X_file = sys.argv[i+1]
    elif sys.argv[i] == "-y":
        Y_file = sys.argv[i+1]
    elif sys.argv[i] == "-k":
        K_file = sys.argv[i+1]
    elif sys.argv[i] == "-m":
        m = int(sys.argv[i+1])
    elif sys.argv[i] == "-mac":
        mac_min = int(sys.argv[i+1])
    elif sys.argv[i] == "-bs":
        batch_size = int(sys.argv[i+1])
    else:
        print('unknown option ' + str(sys.argv[i]))
        quit()

print("loaded commandline args")

start = time.time()

type_K = K_file.split(".")[-1]
type_X = X_file.split(".")[-1]

## load and preprocess genotype matrix 
Y = pd.read_csv(Y_file,index_col=0)

if type_X == 'hdf5' or type_X == 'h5py'  :
    SNP = h5py.File(X_file,'r')
    markers= np.asarray(SNP['positions'])
    acc_X =  np.asarray(SNP['accessions'][:],dtype=np.int)
    acc_Y =  np.asarray(Y[['accesssion_id']]).flatten()
elif type_X == 'csv' :
    X = pd.read_csv(X_file,index_col=0)
    markers = X.columns.values
    acc_X = X.index
    acc_Y = Y.index
    X = np.asarray(X,dtype=np.float32)/2
else :
    sys.exit("Only hdf5, h5py and csv files are supported")



    
if type_K == 'hdf5' or type_K == 'h5py':
    k = h5py.File(K_file,'r')
    acc_K = np.asarray(k['accessions'][:],dtype=np.int)
elif type_K == 'csv':
    k = pd.read_csv(K_file,index_col=0)
    acc_K = k.index
    k = np.array(k, dtype=np.float32)[0:471,0:471]

acc_isec = [isec for isec in acc_X if isec in acc_Y]

idx_acc = list(map(lambda x: x in acc_isec, acc_X))
idy_acc = list(map(lambda x: x in acc_isec, acc_Y))
idk_acc = list(map(lambda x: x in acc_isec, acc_K))

print("data has been imported")

Y_ = np.asarray(Y,dtype=np.float32)[idy_acc,m]

if type_X == 'hdf5' or type_X == 'h5py' :
    X = np.asarray(SNP['snps'][0:(len(SNP['snps'])+1),],dtype=np.float32)[:,idx_acc].T
    k1 = np.asarray(k['kinship'][:])[idk_acc,:]
    K  = k1[:,idk_acc] 
else:
    X  = X[idx_acc,:]
    k1 = k[idk_acc,:]
    K  = k1[:,idk_acc]

## MAF filterin

n = len(Y_)

macs = np.sum(X,axis = 0)
#min_maf_allowed = n * maf_min
#markers_used = markers[mafs > min_maf_allowed]

markers_used  = markers[macs > mac_min]
X = X[:,macs > mac_min]
n_marker = X.shape[1]

## prepare 
K_stand = (n-1)/np.sum((np.identity(n) - np.ones((n,n))/n) * K) * K
q
vg, delta, ve  = herit.estimate(Y_,"normal",K_stand,verbose = False)
## REML

Xo = np.ones(K.shape[0]).flatten()

print(" Pseudo-heritability is " , vg / (ve + vg + delta))
print(" Performing GWAS on ", n , " phenotypes and ", n_marker ," markers with MAF >" , mac_min)

## Transform kinship-matrix, phenotypes and estimate intercept

M = np.transpose(np.linalg.inv(np.linalg.cholesky(vg * K_stand + ve  * np.identity(n)))).astype(np.float32)
Y_t = np.sum(np.multiply(np.transpose(M),Y_),axis=1).astype(np.float32)
int_t = np.sum(np.multiply(np.transpose(M),np.ones(n)),axis=1).astype(np.float32)

## EMMAX Scan
RSS_env = (np.linalg.lstsq(np.reshape(int_t,(n,-1)) , np.reshape(Y_t,(n,-1)))[1]).astype(np.float32)


## calculate betas and se of betas 

def stderr(a,M,Y_t2d,int_t):
    x = tf.stack((int_t,tf.squeeze(tf.matmul(M.T,tf.reshape(a,(n,-1))))),axis=1)
    coeff = tf.matmul(tf.matmul(tf.linalg.inv(tf.matmul(tf.transpose(a=x),x)),tf.transpose(a=x)),Y_t2d)
    SSE = tf.reduce_sum(input_tensor=tf.math.square(tf.math.subtract(Y_t,tf.math.add(tf.math.multiply(x[:,1],coeff[0,0]),tf.math.multiply(x[:,1],coeff[1,0])))))
    SE = tf.math.sqrt(SSE/(471-(1+2)))
    StdERR = tf.sqrt(tf.linalg.diag_part(tf.math.multiply(SE , tf.linalg.inv(tf.matmul(tf.transpose(a=x),x)))))[1]
    return tf.stack((coeff[1,0],StdERR))

## calculate residual sum squares 
def rss(a,M,y,int_t):
    x_t = tf.reduce_sum(input_tensor=tf.math.multiply(M.T,a),axis=1)
    lm_res = tf.linalg.lstsq(tf.transpose(a=tf.stack((int_t,x_t),axis=0)),Y_t2d)
    lm_x = tf.concat((tf.squeeze(lm_res),x_t),axis=0)
    return tf.reduce_sum(input_tensor=tf.math.square(tf.math.subtract(tf.squeeze(Y_t2d),tf.math.add(tf.math.multiply(lm_x[1],lm_x[2:]), tf.multiply(lm_x[0],int_t)))))



for i in range(int(np.ceil(n_marker/batch_size))):
    if n_marker < batch_size:
        X_sub = X
    else:
        lower_limit = batch_size * i 
        upper_limit = batch_size * i + batch_size
        if upper_limit <= n_marker :
            X_sub = X[:,lower_limit:upper_limit]
            print("Working on markers ", lower_limit , " to ", upper_limit, " of ", n_marker )    
        else:
            X_sub = X[:,lower_limit:]
            print("Working on markers ", lower_limit , " to ", n_marker, " of ", n_marker )    
    sess = tf.compat.v1.Session()                                                          
    Y_t2d = tf.cast(tf.reshape(Y_t,(n,-1)),dtype=tf.float32)                     
    y_tensor =  tf.convert_to_tensor(value=Y_t,dtype = tf.float32)                     
    StdERR = tf.map_fn(lambda a : stderr(a,M,Y_t2d,int_t), X_sub.T)              
    R1_full = tf.map_fn(lambda a: rss(a,M,Y_t2d,int_t), X_sub.T)                 
    F_1 = tf.divide(tf.subtract(RSS_env, R1_full),tf.divide(R1_full,(n-3)))      
    if i == 0 :
        output = tf.concat([tf.reshape(F_1,(X_sub.shape[1],-1)),StdERR],axis=1)
    else :
        tmp = tf.concat([tf.reshape(F_1,(X_sub.shape[1],-1)),StdERR],axis=1)
        output = np.append(output,tmp,axis=0)

output = np.array(output)
F_dist = output[:,0]
pval  = 1-f.cdf(F_dist,1,n-3)
output[:,0] = pval



print("done")
 
end = time.time()
print(end - start)


if(type_X == 'csv'):
    chr_pos = np.array(list(map(lambda x : x.split("- "),markers_used)))
else: 
    chr_reg = SNP['positions'].attrs['chr_regions']
    mk_index= np.array(range(len(markers)),dtype=int)[macs > mac_min]
    chr_pos = np.array([list(map(lambda x: sum(x > chr_reg[:,1]) +1, mk_index)), markers_used]).T


pd.DataFrame({
    'chr' : chr_pos[:,0] ,
    'pos' : chr_pos[:,1] , 
    'pval': pval ,
    'mac' : macs[macs > mac_min] ,
    'eff_size': output[:,1] ,
    'SE' : output[:,2]}).to_csv("results.csv",index=False)
